{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea725b02",
   "metadata": {},
   "source": [
    "# Task A "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44107422",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Approach: Floyd's Tortoise and Hare algorithm\n",
    "\n",
    "class ListNode:\n",
    "    def __init__(self, x):\n",
    "        self.val = x\n",
    "        self.next = None\n",
    "\n",
    "class Solution:\n",
    "    def detectCycle(self, head):\n",
    "        slow = head\n",
    "        fast = head\n",
    "\n",
    "        # Step 1: Detect cycle\n",
    "        while fast and fast.next:\n",
    "            slow = slow.next\n",
    "            fast = fast.next.next\n",
    "\n",
    "            if slow == fast:\n",
    "                break\n",
    "        else:\n",
    "            return None   # no cycle\n",
    "\n",
    "        # Step 2: Find cycle start\n",
    "        slow = head\n",
    "        while slow != fast:\n",
    "            slow = slow.next\n",
    "            fast = fast.next\n",
    "\n",
    "        return slow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0233dccc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8e2feae7",
   "metadata": {},
   "source": [
    "# TASK-B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394a69d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- RESPONSE ----\n",
      "**Artificial Intelligence (AI)** is a broad field of computer science dedicated to creating machines that can perform tasks that typically require human intelligence.\n",
      "\n",
      "In simpler terms, **AI is about making computers \"smart\" like humans, enabling them to learn, reason, solve problems, perceive, and understand language.**\n",
      "\n",
      "Here's a breakdown of what that means:\n",
      "\n",
      "1.  **Learning:** AI systems can learn from data, identifying patterns and making decisions or predictions based on those patterns. This is often achieved through **Machine Learning (ML)**, where algorithms are \"trained\" on vast amounts of data.\n",
      "    *   *Example:* An AI system trained on millions of images of cats and dogs can learn to identify new images as either a cat or a dog.\n",
      "\n",
      "2.  **Reasoning:** AI can process information and apply logic to solve problems or make inferences, much like humans do.\n",
      "    *   *Example:* A chess AI can analyze the board state and determine the best move based on its learned strategies and game rules.\n",
      "\n",
      "3.  **Problem-Solving:** AI can be designed to tackle complex problems, often by trying various approaches and learning from successes and failures.\n",
      "    *   *Example:* Route optimization for delivery services, finding the most efficient path.\n",
      "\n",
      "4.  **Perception:** Through technologies like **Computer Vision**, AI can \"see\" and interpret visual information (images, videos), and through **Natural Language Processing (NLP)**, it can \"hear\" and understand spoken or written language.\n",
      "    *   *Example:* Facial recognition systems, self-driving cars detecting pedestrians, voice assistants like Siri or Alexa.\n",
      "\n",
      "5.  **Understanding and Generating Language:** AI can comprehend human language (both written and spoken) and generate coherent and contextually relevant text or speech.\n",
      "    *   *Example:* Chatbots that answer customer questions, translation software, tools like ChatGPT that write articles or code.\n",
      "\n",
      "---\n",
      "\n",
      "**Key Concepts and Branches within AI:**\n",
      "\n",
      "*   **Machine Learning (ML):** A subset of AI focused on systems that learn from data without explicit programming. It's the most common approach to building AI today.\n",
      "    *   **Deep Learning (DL):** A subset of ML that uses artificial neural networks with multiple layers (hence \"deep\") to learn complex patterns, especially in data like images, sound, and text.\n",
      "*   **Natural Language Processing (NLP):** Enables computers to understand, interpret, and generate human language.\n",
      "*   **Computer Vision:** Enables computers to \"see\" and interpret visual information from the world.\n",
      "*   **Robotics:** Involves designing and building robots that can often incorporate AI for tasks like navigation, manipulation, and decision-making.\n",
      "\n",
      "---\n",
      "\n",
      "**Types of AI (by Capability):**\n",
      "\n",
      "1.  **Narrow AI (or Weak AI):** This is the kind of AI that exists today. It's designed and trained for a specific task.\n",
      "    *   *Examples:* Voice assistants (Siri, Alexa), recommendation engines (Netflix, Amazon), self-driving cars, spam filters, medical diagnosis tools. They excel at their specific tasks but cannot perform beyond them.\n",
      "\n",
      "2.  **General AI (AGI or Strong AI):** This is hypothetical AI that would possess human-level cognitive abilities across a wide range of tasks, including learning, reasoning, problem-solving, and understanding. It would be able to perform *any* intellectual task that a human can. AGI does not currently exist.\n",
      "\n",
      "3.  **Superintelligence:** A hypothetical AI that would surpass human intelligence across virtually all fields, including scientific creativity, general wisdom, and social skills. This is a topic of significant futuristic and ethical discussion.\n",
      "\n",
      "---\n",
      "\n",
      "**In essence, AI is about creating intelligent agents that can perceive their environment and take actions that maximize their chance of achieving defined goals.** It's a rapidly evolving field with the potential to transform nearly every aspect of our lives.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "API_KEY=os.getenv(\"GEMINI\")\n",
    "\n",
    "URL = \"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent\"\n",
    "    \n",
    "prompt = \"what is AI\"\n",
    "\n",
    "payload = {\n",
    "    \"contents\": [\n",
    "        {\"parts\": [{\"text\": prompt}]}\n",
    "    ]\n",
    "}\n",
    "\n",
    "res = requests.post(f\"{URL}?key={API_KEY}\", json=payload)\n",
    "data = res.json()\n",
    "\n",
    "if \"candidates\" in data:\n",
    "    print(\"---- RESPONSE ----\")\n",
    "    print(data[\"candidates\"][0][\"content\"][\"parts\"][0][\"text\"])\n",
    "else:\n",
    "    print(\"---- API ERROR ----\")\n",
    "    print(json.dumps(data, indent=2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f0fd1a",
   "metadata": {},
   "source": [
    "# TASK-C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7fc29c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 132 chunks\n",
      "Q: what is Generative AI?\n",
      "A: Generative AI is a subset of artificial intelligence that creates new content from learned patterns in training data. Unlike traditional AI that analyzes or classifies data, generative AI produces original text, images, code, music, or other content. It works by learning statistical patterns from vast datasets and using these patterns to generate contextually relevant outputs.\n"
     ]
    }
   ],
   "source": [
    "# optional \n",
    "\n",
    "\n",
    "from glob import glob\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "os.environ[\"GOOGLE_API_KEY\"]=os.getenv(\"GEMINI\")\n",
    "\n",
    "\n",
    "docs = []\n",
    "for path in glob(r\"C:\\Users\\Windows\\Downloads\\GEN_AI Interview questions.pdf\", recursive=True):\n",
    "    docs.extend(PyPDFLoader(path).load())\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "chunks = splitter.split_documents(docs)\n",
    "\n",
    "print(f\"Loaded {len(chunks)} chunks\")\n",
    "\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"intfloat/e5-small-v2\")\n",
    "\n",
    "\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "emb = GoogleGenerativeAIEmbeddings(model=\"intfloat/e5-small-v2\",task_type=\"retrieval_document\")\n",
    "vectordb = Chroma.from_documents(chunks, \n",
    "                                 embedding=embeddings,\n",
    "                                 )\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "llm= ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")\n",
    "\n",
    "\n",
    "def simple_rag(question):\n",
    "    docs = vectordb.similarity_search_with_score(question, k=3)\n",
    "\n",
    "    if not docs:\n",
    "        return \"I don't have that information in the document.\"\n",
    "\n",
    "    # docs is now: [(Document, score), (Document, score)â€¦]\n",
    "    top_doc, score = docs[0]\n",
    "\n",
    "    if score > 0.7:   # Chroma uses LOWER score = better\n",
    "        return \"I don't have that information in the document.\"\n",
    "\n",
    "    context = \"\\n\\n\".join([doc.page_content for doc, _ in docs])\n",
    "\n",
    "    prompt = f\"\"\"You are a QA bot.\n",
    "\n",
    "Answer ONLY using the context below.\n",
    "If the answer is not found, say:\n",
    "\"I don't have that information in the document.\"\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "    response = llm.invoke(prompt)\n",
    "    return response.content.strip()\n",
    "\n",
    "\n",
    "# Usage\n",
    "question = \"what is Generative AI?\"\n",
    "answer = simple_rag(question)\n",
    "print(\"Q:\", question)\n",
    "print(\"A:\", answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "65d17255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: How does RAG work?\n",
      "Most relevant sentence: RAG improves answers using external documents.\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "model = SentenceTransformer(\"intfloat/e5-small-v2\")\n",
    "\n",
    "sentences = [\n",
    "    \"Machine learning models learn patterns from data.\",\n",
    "    \"The capital of India is New Delhi.\",\n",
    "    \"GenAI models like Gemini and ChatGPT generate text.\",\n",
    "    \"RAG improves answers using external documents.\"\n",
    "]\n",
    "\n",
    "embeddings = model.encode(sentences, convert_to_tensor=True)\n",
    "\n",
    "query = \"How does RAG work?\"\n",
    "query_emb = model.encode(query, convert_to_tensor=True)\n",
    "\n",
    "scores = util.cos_sim(query_emb, embeddings)[0]\n",
    "\n",
    "best_index = scores.argmax().item()\n",
    "\n",
    "print(\"Query:\", query)\n",
    "print(\"Most relevant sentence:\", sentences[best_index])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python langgraph",
   "language": "python",
   "name": "langgraph"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
